#!/usr/bin/env python3
"""
Prometheus Uyumlu Metrik Ä°zleme ModÃ¼lÃ¼

Bu modÃ¼l, AI fonksiyonlarÄ±nÄ±n performansÄ±nÄ± ve kullanÄ±mÄ±nÄ± izlemek iÃ§in
Prometheus uyumlu metrikler saÄŸlar.

Ã–zellikler:
- AI Ã§aÄŸrÄ± sayÄ±sÄ± izleme
- Token kullanÄ±mÄ± izleme
- YanÄ±t sÃ¼resi (latency) izleme
- Model bazlÄ± ayrÄ±ÅŸtÄ±rma
- HTTP endpoint ile metrik eriÅŸimi
"""

import time
import logging
import threading
from typing import Optional, Dict, Any
from contextlib import contextmanager
import argparse
from pathlib import Path
import json
from datetime import datetime

# Prometheus client import
try:
    from prometheus_client import Counter, Histogram, Gauge, start_http_server, generate_latest, CONTENT_TYPE_LATEST
    PROMETHEUS_AVAILABLE = True
except ImportError:
    PROMETHEUS_AVAILABLE = False
    print("UyarÄ±: prometheus_client kÃ¼tÃ¼phanesi bulunamadÄ±. Metrik izleme devre dÄ±ÅŸÄ±.")
    print("Kurulum: pip install prometheus_client")

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MetricsCollector:
    """Prometheus uyumlu metrik toplayÄ±cÄ±"""
    
    def __init__(self):
        self.metrics_initialized = False
        self.metrics_server_running = False
        self.metrics_server_thread = None
        self.metrics_server_port = 9000
        
        # Metrik objeleri
        self.ai_call_counter = None
        self.ai_token_counter = None
        self.ai_latency_histogram = None
        self.ai_active_requests = None
        self.ai_error_counter = None
        
        # Ä°statistikler
        self.stats = {
            'total_calls': 0,
            'total_tokens': 0,
            'total_errors': 0,
            'model_stats': {},
            'last_call_time': None
        }
        
        if PROMETHEUS_AVAILABLE:
            self.init_metrics()
    
    def init_metrics(self):
        """Prometheus metrik objelerini baÅŸlat"""
        if not PROMETHEUS_AVAILABLE:
            logger.warning("Prometheus client mevcut deÄŸil, metrikler devre dÄ±ÅŸÄ±")
            return
        
        try:
            # AI Ã§aÄŸrÄ± sayacÄ± (model bazlÄ±)
            self.ai_call_counter = Counter(
                'ai_calls_total',
                'Toplam AI Ã§aÄŸrÄ± sayÄ±sÄ±',
                ['model', 'action']
            )
            
            # Token kullanÄ±m sayacÄ± (model bazlÄ±)
            self.ai_token_counter = Counter(
                'ai_tokens_total',
                'Toplam token kullanÄ±mÄ±',
                ['model', 'action']
            )
            
            # YanÄ±t sÃ¼resi histogramÄ± (model bazlÄ±)
            self.ai_latency_histogram = Histogram(
                'ai_latency_seconds',
                'AI yanÄ±t sÃ¼resi (saniye)',
                ['model', 'action'],
                buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0]
            )
            
            # Aktif istek sayÄ±sÄ± (model bazlÄ±)
            self.ai_active_requests = Gauge(
                'ai_active_requests',
                'Aktif AI istek sayÄ±sÄ±',
                ['model', 'action']
            )
            
            # Hata sayacÄ± (model bazlÄ±)
            self.ai_error_counter = Counter(
                'ai_errors_total',
                'Toplam AI hata sayÄ±sÄ±',
                ['model', 'action', 'error_type']
            )
            
            self.metrics_initialized = True
            logger.info("Prometheus metrikleri baÅŸlatÄ±ldÄ±")
            
        except Exception as e:
            logger.error(f"Metrik baÅŸlatma hatasÄ±: {e}")
            self.metrics_initialized = False
    
    def log_ai_call(self, model_name: str, action: str, tokens_used: int = 0, 
                   latency: float = 0.0, error_type: Optional[str] = None):
        """
        AI Ã§aÄŸrÄ±sÄ±nÄ± logla ve metrikleri gÃ¼ncelle
        
        Args:
            model_name: AI model adÄ± (openai, gemini, vb.)
            action: YapÄ±lan iÅŸlem (summarize, cluster, classify, vb.)
            tokens_used: KullanÄ±lan token sayÄ±sÄ±
            latency: YanÄ±t sÃ¼resi (saniye)
            error_type: Hata tipi (varsa)
        """
        try:
            # Ä°statistikleri gÃ¼ncelle
            self.stats['total_calls'] += 1
            self.stats['total_tokens'] += tokens_used
            self.stats['last_call_time'] = datetime.now().isoformat()
            
            # Model bazlÄ± istatistikler
            if model_name not in self.stats['model_stats']:
                self.stats['model_stats'][model_name] = {
                    'calls': 0,
                    'tokens': 0,
                    'errors': 0,
                    'total_latency': 0.0
                }
            
            self.stats['model_stats'][model_name]['calls'] += 1
            self.stats['model_stats'][model_name]['tokens'] += tokens_used
            self.stats['model_stats'][model_name]['total_latency'] += latency
            
            if error_type:
                self.stats['total_errors'] += 1
                self.stats['model_stats'][model_name]['errors'] += 1
            
            # Prometheus metriklerini gÃ¼ncelle
            if self.metrics_initialized:
                # Ã‡aÄŸrÄ± sayacÄ±
                self.ai_call_counter.labels(model=model_name, action=action).inc()
                
                # Token sayacÄ±
                if tokens_used > 0:
                    self.ai_token_counter.labels(model=model_name, action=action).inc(tokens_used)
                
                # YanÄ±t sÃ¼resi histogramÄ±
                if latency > 0:
                    self.ai_latency_histogram.labels(model=model_name, action=action).observe(latency)
                
                # Hata sayacÄ±
                if error_type:
                    self.ai_error_counter.labels(
                        model=model_name, 
                        action=action, 
                        error_type=error_type
                    ).inc()
            
            logger.info(f"AI Ã§aÄŸrÄ±sÄ± loglandÄ±: {model_name}/{action} - "
                       f"Token: {tokens_used}, SÃ¼re: {latency:.3f}s")
            
        except Exception as e:
            logger.error(f"Metrik loglama hatasÄ±: {e}")
    
    @contextmanager
    def track_ai_call(self, model_name: str, action: str):
        """
        AI Ã§aÄŸrÄ±sÄ±nÄ± otomatik olarak izleyen context manager
        
        Usage:
            with metrics.track_ai_call("openai", "summarize"):
                # AI Ã§aÄŸrÄ±sÄ± burada yapÄ±lÄ±r
                result = ai_helper.summarize_texts(texts)
        """
        start_time = time.time()
        error_type = None
        
        try:
            # Aktif istek sayÄ±sÄ±nÄ± artÄ±r
            if self.metrics_initialized:
                self.ai_active_requests.labels(model=model_name, action=action).inc()
            
            yield
            
        except Exception as e:
            error_type = type(e).__name__
            raise
            
        finally:
            # Aktif istek sayÄ±sÄ±nÄ± azalt
            if self.metrics_initialized:
                self.ai_active_requests.labels(model=model_name, action=action).dec()
            
            # Metrikleri logla
            latency = time.time() - start_time
            self.log_ai_call(model_name, action, latency=latency, error_type=error_type)
    
    def start_metrics_server(self, port: int = 9000, host: str = '0.0.0.0'):
        """
        Prometheus metrik sunucusunu baÅŸlat
        
        Args:
            port: Sunucu portu
            host: Sunucu host adresi
        """
        if not PROMETHEUS_AVAILABLE:
            logger.error("Prometheus client mevcut deÄŸil, metrik sunucusu baÅŸlatÄ±lamÄ±yor")
            return False
        
        if self.metrics_server_running:
            logger.warning("Metrik sunucusu zaten Ã§alÄ±ÅŸÄ±yor")
            return True
        
        try:
            def start_server():
                try:
                    start_http_server(port, addr=host)
                    logger.info(f"Prometheus metrik sunucusu baÅŸlatÄ±ldÄ±: http://{host}:{port}/metrics")
                except Exception as e:
                    logger.error(f"Metrik sunucusu baÅŸlatma hatasÄ±: {e}")
            
            # AyrÄ± thread'de baÅŸlat
            self.metrics_server_thread = threading.Thread(target=start_server, daemon=True)
            self.metrics_server_thread.start()
            
            self.metrics_server_running = True
            self.metrics_server_port = port
            
            return True
            
        except Exception as e:
            logger.error(f"Metrik sunucusu baÅŸlatma hatasÄ±: {e}")
            return False
    
    def stop_metrics_server(self):
        """Metrik sunucusunu durdur"""
        if self.metrics_server_running:
            logger.info("Metrik sunucusu durduruldu")
            self.metrics_server_running = False
    
    def get_metrics_summary(self) -> Dict[str, Any]:
        """Mevcut metrik Ã¶zetini dÃ¶ndÃ¼r"""
        summary = {
            'metrics_enabled': self.metrics_initialized,
            'server_running': self.metrics_server_running,
            'server_port': self.metrics_server_port,
            'stats': self.stats.copy(),
            'prometheus_available': PROMETHEUS_AVAILABLE
        }
        
        # Model bazlÄ± Ã¶zet istatistikler
        if self.stats['model_stats']:
            summary['model_summary'] = {}
            for model, stats in self.stats['model_stats'].items():
                avg_latency = stats['total_latency'] / stats['calls'] if stats['calls'] > 0 else 0
                summary['model_summary'][model] = {
                    'total_calls': stats['calls'],
                    'total_tokens': stats['tokens'],
                    'total_errors': stats['errors'],
                    'avg_latency': round(avg_latency, 3),
                    'error_rate': round(stats['errors'] / stats['calls'] * 100, 2) if stats['calls'] > 0 else 0
                }
        
        return summary
    
    def export_metrics(self, output_file: str = None) -> str:
        """
        Metrikleri JSON dosyasÄ±na dÄ±ÅŸa aktar
        
        Args:
            output_file: Ã‡Ä±ktÄ± dosya adÄ± (opsiyonel)
            
        Returns:
            Kaydedilen dosya yolu
        """
        if not output_file:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"metrics_export_{timestamp}.json"
        
        try:
            metrics_data = self.get_metrics_summary()
            metrics_data['export_time'] = datetime.now().isoformat()
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(metrics_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"Metrikler dÄ±ÅŸa aktarÄ±ldÄ±: {output_file}")
            return output_file
            
        except Exception as e:
            logger.error(f"Metrik dÄ±ÅŸa aktarma hatasÄ±: {e}")
            return ""
    
    def reset_metrics(self):
        """TÃ¼m metrikleri sÄ±fÄ±rla"""
        self.stats = {
            'total_calls': 0,
            'total_tokens': 0,
            'total_errors': 0,
            'model_stats': {},
            'last_call_time': None
        }
        logger.info("Metrikler sÄ±fÄ±rlandÄ±")

# Global metrics instance
_metrics_collector = None

def get_metrics_collector() -> MetricsCollector:
    """Global metrics collector instance'Ä±nÄ± dÃ¶ndÃ¼r"""
    global _metrics_collector
    if _metrics_collector is None:
        _metrics_collector = MetricsCollector()
    return _metrics_collector

def log_ai_call(model_name: str, action: str, tokens_used: int = 0, 
               latency: float = 0.0, error_type: Optional[str] = None):
    """Global AI Ã§aÄŸrÄ± loglama fonksiyonu"""
    collector = get_metrics_collector()
    collector.log_ai_call(model_name, action, tokens_used, latency, error_type)

@contextmanager
def track_ai_call(model_name: str, action: str):
    """Global AI Ã§aÄŸrÄ± izleme context manager'Ä±"""
    collector = get_metrics_collector()
    with collector.track_ai_call(model_name, action):
        yield

def start_metrics_server(port: int = 9000, host: str = '0.0.0.0') -> bool:
    """Global metrik sunucusu baÅŸlatma fonksiyonu"""
    collector = get_metrics_collector()
    return collector.start_metrics_server(port, host)

def get_metrics_summary() -> Dict[str, Any]:
    """Global metrik Ã¶zeti alma fonksiyonu"""
    collector = get_metrics_collector()
    return collector.get_metrics_summary()

def export_metrics(output_file: str = None) -> str:
    """Global metrik dÄ±ÅŸa aktarma fonksiyonu"""
    collector = get_metrics_collector()
    return collector.export_metrics(output_file)

def reset_metrics():
    """Global metrik sÄ±fÄ±rlama fonksiyonu"""
    collector = get_metrics_collector()
    collector.reset_metrics()

def main():
    """CLI arayÃ¼zÃ¼"""
    parser = argparse.ArgumentParser(description="Prometheus Uyumlu Metrik Ä°zleme Sistemi")
    parser.add_argument('--action', choices=['start-server', 'summary', 'export', 'reset', 'test'],
                       default='summary', help='YapÄ±lacak iÅŸlem')
    parser.add_argument('--port', type=int, default=9000, help='Metrik sunucusu portu')
    parser.add_argument('--host', default='0.0.0.0', help='Metrik sunucusu host adresi')
    parser.add_argument('--output', help='DÄ±ÅŸa aktarma dosya adÄ±')
    
    args = parser.parse_args()
    
    collector = get_metrics_collector()
    
    if args.action == 'start-server':
        success = collector.start_metrics_server(args.port, args.host)
        if success:
            print(f"âœ… Metrik sunucusu baÅŸlatÄ±ldÄ±: http://{args.host}:{args.port}/metrics")
            print("Sunucuyu durdurmak iÃ§in Ctrl+C tuÅŸlayÄ±n...")
            try:
                # Sunucuyu Ã§alÄ±ÅŸÄ±r durumda tut
                while True:
                    time.sleep(1)
            except KeyboardInterrupt:
                print("\nğŸ›‘ Metrik sunucusu durduruldu")
        else:
            print("âŒ Metrik sunucusu baÅŸlatÄ±lamadÄ±")
    
    elif args.action == 'summary':
        summary = collector.get_metrics_summary()
        print("ğŸ“Š Metrik Ã–zeti:")
        print(f"  Metrikler Aktif: {summary['metrics_enabled']}")
        print(f"  Sunucu Ã‡alÄ±ÅŸÄ±yor: {summary['server_running']}")
        print(f"  Sunucu Portu: {summary['server_port']}")
        print(f"  Prometheus Mevcut: {summary['prometheus_available']}")
        print(f"  Toplam Ã‡aÄŸrÄ±: {summary['stats']['total_calls']}")
        print(f"  Toplam Token: {summary['stats']['total_tokens']}")
        print(f"  Toplam Hata: {summary['stats']['total_errors']}")
        
        if summary['stats']['last_call_time']:
            print(f"  Son Ã‡aÄŸrÄ±: {summary['stats']['last_call_time']}")
        
        if 'model_summary' in summary:
            print("\nğŸ“ˆ Model BazlÄ± Ä°statistikler:")
            for model, stats in summary['model_summary'].items():
                print(f"  {model.upper()}:")
                print(f"    Ã‡aÄŸrÄ±: {stats['total_calls']}")
                print(f"    Token: {stats['total_tokens']}")
                print(f"    Hata: {stats['total_errors']} ({stats['error_rate']}%)")
                print(f"    Ort. SÃ¼re: {stats['avg_latency']}s")
    
    elif args.action == 'export':
        output_file = collector.export_metrics(args.output)
        if output_file:
            print(f"âœ… Metrikler dÄ±ÅŸa aktarÄ±ldÄ±: {output_file}")
        else:
            print("âŒ Metrik dÄ±ÅŸa aktarma hatasÄ±")
    
    elif args.action == 'reset':
        collector.reset_metrics()
        print("âœ… Metrikler sÄ±fÄ±rlandÄ±")
    
    elif args.action == 'test':
        print("ğŸ§ª Test metrikleri oluÅŸturuluyor...")
        
        # Test Ã§aÄŸrÄ±larÄ±
        with collector.track_ai_call("openai", "summarize"):
            time.sleep(0.5)  # SimÃ¼le edilmiÅŸ iÅŸlem
        
        with collector.track_ai_call("gemini", "classify"):
            time.sleep(0.3)  # SimÃ¼le edilmiÅŸ iÅŸlem
        
        # Hata simÃ¼lasyonu
        try:
            with collector.track_ai_call("openai", "cluster"):
                raise Exception("Test hatasÄ±")
        except:
            pass
        
        print("âœ… Test metrikleri oluÅŸturuldu")
        print("Ã–zet iÃ§in: python metrics.py --action summary")

if __name__ == "__main__":
    main() 